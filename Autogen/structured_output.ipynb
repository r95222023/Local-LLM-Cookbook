{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured Output with Autogen Agent\n",
    "Structuring the output of Large Language Models (LLMs) offers numerous benefits, including improved accuracy, enhanced decision-making, and increased efficiency. Structured output enables models to capture subtle nuances and complexities in language, leading to more accurate predictions or classifications. Consistency is another crucial aspect of structured output for LLMs, offering advantages such as easier comparison, simplified analysis, improved debugging, enhanced reproducibility, and increased stability.\n",
    "\n",
    "AutoGen provides a unified multi-agent conversation framework as a high-level abstraction for using foundation models. However, it does not offer an easy way to produce structured output. This notebook presents a workaround that utilizes agent tool calling to structure the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "from autogen import ConversableAgent, AssistantAgent, UserProxyAgent\n",
    "from autogen import register_function\n",
    "from typing_extensions import Annotated\n",
    "\n",
    "config_list = [\n",
    "    {\n",
    "        \"model\": \"mistral-nemo\",\n",
    "        \"base_url\": \"http://localhost:11434/v1\",\n",
    "        \"api_key\": \"ollama\",\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "llm = ChatOllama(model=\"llama3.1\", temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tool that compels the LLM to generate structured data and validate it to ensure it conforms to the schema.\n",
    "def get_structured_output(name: Annotated[str, \"name\"], height: Annotated[float, \"height in cm\"],\n",
    "                          hair_color: Annotated[str, \"hair color\"],\n",
    "                          age: Annotated[int, \"age\"]) -> Annotated[str, \"Person info.\"]:\n",
    "    res = {name: name, height: height, hair_color: hair_color, age: age}\n",
    "    if name and height and hair_color and age:\n",
    "        return 'The output structure is correct'\n",
    "    else:\n",
    "        return 'The output structure is incorrect'\n",
    "\n",
    "def check_terminate(msg):\n",
    "    print(msg)\n",
    "    if '[TERMINATE]' in msg:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "personal_info_extractor = ConversableAgent(\"personal_info_extractor\",\n",
    "                        system_message=\"You are a smart agent. \"\n",
    "                                    \"You learned each person's height, hair color and age from the \"\n",
    "                                    \"context and find the most matched person.\"\n",
    "                                    \"call get_structured_output(name, height, hair_color, age).\",\n",
    "                        llm_config={\"config_list\": config_list}, max_consecutive_auto_reply=1,\n",
    "                        human_input_mode=\"NEVER\",)\n",
    "user_proxy = ConversableAgent(\"user_proxy\", \n",
    "                        default_auto_reply=\"Did you get correct result from tool calls, answer [TERMINATE] if you got correct result.\",\n",
    "                        is_termination_msg=check_terminate)\n",
    "\n",
    "register_function(\n",
    "        get_structured_output,\n",
    "        caller=personal_info_extractor,\n",
    "        executor=user_proxy,\n",
    "        name=\"get_structured_output\",\n",
    "        description=\"Get structured output.\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to personal_info_extractor):\n",
      "\n",
      "Alex is a 36 year-old man who is 6 feet tall and has blonde hair. Claudia is a 25 year-old brunette woman who is 5 feet tall. Extract people from the sentence\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mpersonal_info_extractor\u001b[0m (to user_proxy):\n",
      "\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_gqjx1jqh): get_structured_output *****\u001b[0m\n",
      "Arguments: \n",
      "{\"age\":36,\"hair_color\":\"blonde\",\"height\":182.88,\"name\":\"Alex\"}\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\u001b[32m***** Suggested tool call (call_p25jqyvc): get_structured_output *****\u001b[0m\n",
      "Arguments: \n",
      "{\"age\":25,\"hair_color\":\"brunette\",\"height\":152.4,\"name\":\"Claudia\"}\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "{'content': '', 'tool_calls': [{'id': 'call_gqjx1jqh', 'function': {'arguments': '{\"age\":36,\"hair_color\":\"blonde\",\"height\":182.88,\"name\":\"Alex\"}', 'name': 'get_structured_output'}, 'type': 'function'}, {'id': 'call_p25jqyvc', 'function': {'arguments': '{\"age\":25,\"hair_color\":\"brunette\",\"height\":152.4,\"name\":\"Claudia\"}', 'name': 'get_structured_output'}, 'type': 'function'}], 'role': 'assistant'}\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION get_structured_output...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[runtime logging] log_function_use: autogen logger is None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION get_structured_output...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[runtime logging] log_function_use: autogen logger is None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to personal_info_extractor):\n",
      "\n",
      "\u001b[33muser_proxy\u001b[0m (to personal_info_extractor):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_gqjx1jqh) *****\u001b[0m\n",
      "The output structure is correct\n",
      "\u001b[32m******************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33muser_proxy\u001b[0m (to personal_info_extractor):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_p25jqyvc) *****\u001b[0m\n",
      "The output structure is correct\n",
      "\u001b[32m******************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = user_proxy.initiate_chat(personal_info_extractor, message=\"Alex is a 36 year-old man who is 6 feet tall and has blonde hair. \"\n",
    "                                       \"Claudia is a 25 year-old brunette woman who is 5 feet tall. Extract people from the sentence\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': 'Alex is a 36 year-old man who is 6 feet tall and has blonde hair. Claudia is a 25 year-old brunette woman who is 5 feet tall. Extract people from the sentence', 'role': 'assistant'}, {'content': '', 'tool_calls': [{'id': 'call_gqjx1jqh', 'function': {'arguments': '{\"age\":36,\"hair_color\":\"blonde\",\"height\":182.88,\"name\":\"Alex\"}', 'name': 'get_structured_output'}, 'type': 'function'}, {'id': 'call_p25jqyvc', 'function': {'arguments': '{\"age\":25,\"hair_color\":\"brunette\",\"height\":152.4,\"name\":\"Claudia\"}', 'name': 'get_structured_output'}, 'type': 'function'}], 'role': 'assistant'}, {'content': 'The output structure is correct\\n\\nThe output structure is correct', 'tool_responses': [{'tool_call_id': 'call_gqjx1jqh', 'role': 'tool', 'content': 'The output structure is correct'}, {'tool_call_id': 'call_p25jqyvc', 'role': 'tool', 'content': 'The output structure is correct'}], 'role': 'tool'}], summary='The output structure is correct\\n\\nThe output structure is correct', cost={'usage_including_cached_inference': {'total_cost': 0, 'mistral-nemo': {'cost': 0, 'prompt_tokens': 180, 'completion_tokens': 94, 'total_tokens': 274}}, 'usage_excluding_cached_inference': {'total_cost': 0}}, human_input=[])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def structure_output(response):\n",
    "    structured_outputs = []\n",
    "    for chat in response.chat_history:\n",
    "        tool_calls = []\n",
    "        # find last tools calls\n",
    "        if 'tool_calls' in chat:\n",
    "            tool_calls = chat['tool_calls']\n",
    "        for tool_call in tool_calls:\n",
    "            args = tool_call['function']['arguments']\n",
    "            structured_output = json.loads(args)\n",
    "            structured_outputs.append(structured_output)\n",
    "    return structured_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'age': 36, 'hair_color': 'blonde', 'height': 182.88, 'name': 'Alex'},\n",
       " {'age': 25, 'hair_color': 'brunette', 'height': 152.4, 'name': 'Claudia'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# found two people, Alex and Claudia with structured output\n",
    "structure_output(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
